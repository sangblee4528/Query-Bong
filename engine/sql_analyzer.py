"""
SQL Query to JSON Converter (AST Based)
ì—­í• : ì›ë³¸ SQLì„ sqlglot ASTë¡œ ë¶„ì„í•˜ì—¬ JSON í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜ ë° íŒŒì¼ ì´ë™ ì²˜ë¦¬
"""

import os
import sys
import json
import shutil
import hashlib
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional

try:
    import sqlglot
    from sqlglot import exp, parse_one
    from sqlglot.optimizer import optimize
except ImportError:
    print("âŒ sqlglot íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install sqlglot")
    sys.exit(1)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ ë° ì„¤ì • ë¡œë“œ
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)
from config.loader import CFG

class SQLQueryAnalyzer:
    """sqlglot AST ê¸°ë°˜ SQL ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.source_dir = CFG.get('SOURCE_PATH')
        self.inbox_dir = os.path.join(self.source_dir, 'inbox')
        self.success_dir = os.path.join(self.source_dir, 'success')
        self.failed_dir = os.path.join(self.source_dir, 'failed')
        self.output_dir = CFG.get('TEMPLATES_PATH')
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        for d in [self.inbox_dir, self.success_dir, self.failed_dir, self.output_dir]:
            os.makedirs(d, exist_ok=True)
            
    def _generate_identity_hash(self, from_table: str, select_exprs: List[str]) -> str:
        """ì¿¼ë¦¬ ì‹ë³„ì„ ìœ„í•œ í•´ì‹œ ìƒì„± (FROM + SELECT ì¡°í•©)"""
        content = f"{from_table}|{'|'.join(sorted(select_exprs))}"
        return hashlib.md5(content.encode()).hexdigest()

    def analyze_file(self, filename: str) -> bool:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„ ë° ì²˜ë¦¬ (Move logic í¬í•¨)"""
        filepath = os.path.join(self.inbox_dir, filename)
        if not os.path.exists(filepath):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {filepath}")
            return False
            
        print(f"ğŸ” ë¶„ì„ ì‹œì‘: {filename}")
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                sql_content = f.read().strip()
                
            if not sql_content:
                raise ValueError("ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤.")

            # AST íŒŒì‹±
            parsed = parse_one(sql_content)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (íŒŒì¼ëª… ê¸°ë°˜)
            file_stem = os.path.splitext(filename)[0]
            # q001_ì„¤ëª….sql -> id: q001
            query_id = file_stem.split('_')[0] if '_' in file_stem else file_stem
            question = file_stem.replace('_', ' ')
            
            # ë¶„ì„ ì‹¤í–‰
            result_json = self._analyze_ast(parsed, query_id, question, sql_content)
            
            # JSON ì €ì¥
            output_path = os.path.join(self.output_dir, f"query_{query_id}.json")
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result_json, f, indent=2, ensure_ascii=False)
            
            # ì„±ê³µ ì²˜ë¦¬: Move to Success
            shutil.move(filepath, os.path.join(self.success_dir, filename))
            print(f"âœ… ë¶„ì„ ì„±ê³µ ë° ì´ë™ ì™„ë£Œ: {filename} -> success/")
            return True
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {filename} - {str(e)}")
            # ì‹¤íŒ¨ ì²˜ë¦¬: Move to Failed
            try:
                shutil.move(filepath, os.path.join(self.failed_dir, filename))
                
                # ì—ëŸ¬ ë¡œê·¸ ì‘ì„±
                log_path = os.path.join(self.failed_dir, f"{filename}.error.log")
                with open(log_path, 'w', encoding='utf-8') as f:
                    f.write(traceback.format_exc())
                print(f"âš ï¸ ì‹¤íŒ¨ íŒŒì¼ ì´ë™ ì™„ë£Œ: {filename} -> failed/")
            except Exception as move_error:
                print(f"ğŸ’€ íŒŒì¼ ì´ë™ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {move_error}")
            return False

    def _analyze_ast(self, ast: exp.Expression, query_id: str, question: str, original_sql: str) -> Dict[str, Any]:
        """AST ìˆœíšŒ ë° ë°ì´í„° êµ¬ì¡°í™”"""
        
        # 1. Initialization
        select_columns = []
        joins = []
        where_conditions = []
        group_by = []
        order_by = []
        from_table = "Unknown"
        
        # 2. Extract FROM
        from_exp = ast.find(exp.From)
        if from_exp:
            for source in from_exp.find_all(exp.Table):
                from_table = source.sql()
                break # Main table only
                
        # 3. Extract SELECT (Flexible Area)
        for projection in ast.find_all(exp.Select):
            for expression in projection.expressions:
                if isinstance(expression, exp.Alias):
                    alias = expression.alias
                    expr_sql = expression.this.sql()
                    # ê°„ë‹¨í•œ aggregation ì²´í¬
                    agg = None
                    if expression.find(exp.AggFunc):
                        agg = expression.find(exp.AggFunc).sql()
                    
                    select_columns.append({
                        "alias": alias,
                        "expression": expr_sql,
                        "table": from_table, # ë‹¨ìˆœí™” (ì‹¤ì œë¡œëŠ” ë§¤í•‘ í•„ìš”)
                        "column": expr_sql,
                        "aggregation": agg
                    })
                elif isinstance(expression, exp.Column):
                    select_columns.append({
                        "alias": expression.name,
                        "expression": expression.sql(),
                        "table": expression.table,
                        "column": expression.name,
                        "aggregation": None
                    })
            break # Main query select only

        # 4. Extract JOINs (Fixed Area)
        for join in ast.find_all(exp.Join):
            # sqlglot versions vary; safer to access via args
            join_kind = join.args.get("kind")
            join_type = join_kind.sql() if join_kind else "INNER"
            
            table = join.this.sql()
            
            on_arg = join.args.get("on") 
            on_cond = on_arg.sql() if on_arg else ""
            
            joins.append({
                "type": join_type,
                "table": table,
                "on_condition": on_cond,
                "relationship": on_cond # ë‹¨ìˆœ ë¡œì§
            })

        # 5. Extract WHERE (Change Area)
        if ast.find(exp.Where):
            # ìˆœíšŒí•˜ë©° ì¡°ê±´ ì¶”ì¶œ
            where_node = ast.find(exp.Where)
            
            # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  ì¡°ê±´ì ˆì„ íƒìƒ‰í•˜ê¸°ë³´ë‹¤, ìµœìƒìœ„ AND ì¡°ê±´ë“¤ë§Œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì´ìƒì ì¼ ìˆ˜ ìˆìœ¼ë‚˜
            # í˜„ì¬ ë¡œì§ì€ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ í‰íƒ„í™”ëœ ì¡°ê±´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•¨
            
            for cond in where_node.find_all(exp.EQ, exp.GT, exp.LT, exp.GTE, exp.LTE, exp.NEQ, exp.In, exp.Between):
                col = ""
                val = ""
                operator = ""
                cond_type = "filter"
                
                if isinstance(cond, exp.Between):
                    operator = "BETWEEN"
                    col = cond.this.sql()
                    low = cond.args.get('low')
                    high = cond.args.get('high')
                    val = f"{low.sql()} AND {high.sql()}" if low and high else "Unknown"
                    
                elif isinstance(cond, exp.In):
                    operator = "IN"
                    col = cond.this.sql()
                    # args['expressions'] is a list of expressions
                    in_values = [e.sql() for e in cond.args.get('expressions', [])]
                    val = f"({', '.join(in_values)})"
                    
                else:
                    # Binary Operators (EQ, GT, LT ...)
                    if isinstance(cond, exp.EQ): operator = "="
                    elif isinstance(cond, exp.GT): operator = ">"
                    elif isinstance(cond, exp.LT): operator = "<"
                    elif isinstance(cond, exp.GTE): operator = ">="
                    elif isinstance(cond, exp.LTE): operator = "<="
                    elif isinstance(cond, exp.NEQ): operator = "<>"
                    
                    col = cond.this.sql()
                    val = cond.expression.sql() 
                    
                where_conditions.append({
                    "column": col,
                    "operator": operator,
                    "value": val,
                    "type": "filter"
                })

        # 6. Extract GROUP BY
        if ast.find(exp.Group):
            for grp in ast.find(exp.Group).expressions:
                group_by.append(grp.sql())

        # 7. Extract ORDER BY
        if ast.find(exp.Order):
            for ord in ast.find(exp.Order).expressions:
                order_by.append(ord.sql())
        
        # 8. Classification (Unit Logic)
        # Driven Table ê¸°ì¤€ (LEFT/RIGHT OUTER ì œì™¸, INNER JOINë§Œ ì¹´ìš´íŠ¸)
        unit_type = "unitA"
        
        # ê¸°ë³¸: FROM Table (1ê°œ)
        # INNER JOINëœ í…Œì´ë¸”ë§Œ ì¹´ìš´íŠ¸ì— í¬í•¨
        inner_join_tables = [j['table'] for j in joins if "LEFT" not in j['type'].upper() and "RIGHT" not in j['type'].upper() and "OUTER" not in j['type'].upper()]
        
        # ìœ íš¨ ì—”í‹°í‹° ìˆ˜ = Main + Inner Joins
        effective_entity_count = 1 + len(inner_join_tables)

        if effective_entity_count >= 3:
            unit_type = "unitC"
        elif effective_entity_count == 2:
            unit_type = "unitB"
        else:
            unit_type = "unitA"
        # 9. Construct JSON
        return {
            "query_id": query_id,
            "question": question,
            "description": "Auto-analyzed by sqlglot",
            "unit_type": unit_type,
            "unit_description": "Automated Unit Classification",
            "entities": list(set(entities)),
            "presentation_type": "table",
            "presentation_config": {},
            "sql": {
                "original": original_sql,
                "normalized": ast.sql(),
                "structure": {
                    "select_columns": select_columns,
                    "from_table": from_table,
                    "joins": joins,
                    "where_conditions": where_conditions,
                    "group_by": group_by,
                    "order_by": order_by
                }
            },
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "tags": entities,
                "complexity": "low",
                "estimated_rows": "unknown"
            }
        }

    def process_inbox(self):
        """Inboxì˜ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬"""
        files = [f for f in os.listdir(self.inbox_dir) if f.endswith('.sql') or f.endswith('.txt')]
        if not files:
            print("ğŸ“­ Inboxê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return
            
        print(f"ğŸš€ Inbox ì²˜ë¦¬ ì‹œì‘ ({len(files)}ê°œ íŒŒì¼)...")
        success_count = 0
        
        for f in files:
            if self.analyze_file(f):
                success_count += 1
                
        print(f"\nâœ¨ ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {success_count} / ì „ì²´ {len(files)}")


if __name__ == "__main__":
    analyzer = SQLQueryAnalyzer()
    analyzer.process_inbox()
